#!/usr/bin/env tsx

import { readdir, readFile } from 'node:fs/promises';
import path from 'node:path';
import { fileURLToPath } from 'node:url';
import { config as loadEnv } from 'dotenv';

// åŠ è½½ç¯å¢ƒå˜é‡
['.env.local', '.env']
  .map(file => path.resolve(process.cwd(), file))
  .forEach(envPath => {
    loadEnv({ path: envPath, override: false });
  });

const KNOWLEDGE_DIR = path.resolve(
  path.dirname(fileURLToPath(import.meta.url)),
  '../../tmp/knowledge'
);

const API_BASE_URL = process.env.API_BASE_URL || 'http://localhost:3000/api/v1';
const DEFAULT_MAX_TOKENS = Number.parseInt(
  process.env.KNOWLEDGE_MAX_TOKENS ?? '1800',
  10
);
let maxTokensPerChunk = Number.isFinite(DEFAULT_MAX_TOKENS)
  ? DEFAULT_MAX_TOKENS
  : 1800;

interface Chunk {
  content: string;
  order: number;
  tokenCount?: number;
  metadata?: Record<string, unknown>;
}

interface Document {
  externalId: string;
  title: string;
  sourceUrl?: string;
  version?: string;
  metadata?: Record<string, unknown>;
}

/**
 * å°†Markdownæ–‡æœ¬åˆ†å‰²æˆchunks
 * æŒ‰æ ‡é¢˜å’Œæ®µè½åˆ†å‰²ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§
 */
function splitMarkdown(content: string, maxChunkSize = 1000): Chunk[] {
  const chunks: Chunk[] = [];
  const lines = content.split('\n');
  let currentChunk = '';
  let currentOrder = 0;
  let currentSection = '';

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i];
    const trimmed = line.trim();

    // æ£€æµ‹æ ‡é¢˜
    if (trimmed.startsWith('#')) {
      // å¦‚æœå½“å‰chunkæœ‰å†…å®¹ï¼Œå…ˆä¿å­˜
      if (currentChunk.trim()) {
        chunks.push({
          content: currentChunk.trim(),
          order: currentOrder++,
          metadata: currentSection ? { section: currentSection } : undefined,
        });
        currentChunk = '';
      }

      // æå–æ ‡é¢˜ä½œä¸ºsectionæ ‡è¯†
      currentSection = trimmed.replace(/^#+\s*/, '');
      // æ ‡é¢˜ä¹Ÿä½œä¸ºchunkçš„ä¸€éƒ¨åˆ†
      currentChunk = line + '\n';
    } else if (trimmed) {
      // éç©ºè¡Œæ·»åŠ åˆ°å½“å‰chunk
      currentChunk += line + '\n';
    } else {
      // ç©ºè¡Œï¼Œå¦‚æœå½“å‰chunkè¾ƒå¤§åˆ™åˆ†å‰²
      if (currentChunk.length > maxChunkSize) {
        chunks.push({
          content: currentChunk.trim(),
          order: currentOrder++,
          metadata: currentSection ? { section: currentSection } : undefined,
        });
        currentChunk = '';
      } else {
        currentChunk += '\n';
      }
    }

    // å¦‚æœchunkè¶…è¿‡æœ€å¤§å¤§å°ï¼Œå¼ºåˆ¶åˆ†å‰²
    if (currentChunk.length > maxChunkSize * 1.5) {
      const parts = splitByParagraph(currentChunk, maxChunkSize);
      for (let j = 0; j < parts.length - 1; j++) {
        chunks.push({
          content: parts[j].trim(),
          order: currentOrder++,
          metadata: currentSection ? { section: currentSection } : undefined,
        });
      }
      currentChunk = parts[parts.length - 1];
    }
  }

  // ä¿å­˜æœ€åä¸€ä¸ªchunk
  if (currentChunk.trim()) {
    chunks.push({
      content: currentChunk.trim(),
      order: currentOrder++,
      metadata: currentSection ? { section: currentSection } : undefined,
    });
  }

  return chunks.filter(chunk => chunk.content.length > 0);
}

/**
 * æŒ‰æ®µè½åˆ†å‰²æ–‡æœ¬
 */
function splitByParagraph(text: string, maxSize: number): string[] {
  const parts: string[] = [];
  const paragraphs = text.split(/\n\n+/);

  let current = '';
  for (const para of paragraphs) {
    if (current.length + para.length > maxSize && current) {
      parts.push(current);
      current = para;
    } else {
      current += (current ? '\n\n' : '') + para;
    }
  }
  if (current) {
    parts.push(current);
  }

  return parts.length > 0 ? parts : [text];
}

/**
 * ä»æ–‡ä»¶åæå–æ ‡é¢˜ï¼ˆå»æ‰æ‰©å±•åå’Œç‰¹æ®Šå­—ç¬¦ï¼‰
 */
function extractTitle(filename: string, content: string): string {
  // å°è¯•ä»å†…å®¹ç¬¬ä¸€è¡Œæå–æ ‡é¢˜
  const firstLine = content.split('\n')[0]?.trim();
  if (firstLine?.startsWith('# ')) {
    return firstLine.replace(/^#\s+/, '');
  }

  // ä»æ–‡ä»¶åæå–
  const baseName = path.basename(filename, '.md');
  return baseName
    .replace(/[-_]/g, ' ')
    .replace(/\b\w/g, l => l.toUpperCase())
    .trim();
}

/**
 * å¯¼å…¥å•ä¸ªMarkdownæ–‡ä»¶
 */
async function ingestMarkdownFile(
  filePath: string,
  generateEmbeddings = true
): Promise<void> {
  const filename = path.basename(filePath);
  const content = await readFile(filePath, 'utf-8');
  const title = extractTitle(filename, content);
  const externalId = `md-${path.basename(filePath, '.md')}`;

  // åˆ†å‰²æˆchunks
  const rawChunks = splitMarkdown(content);
  const chunks = enforceTokenLimit(rawChunks, maxTokensPerChunk);

  if (chunks.length === 0) {
    console.warn(`âš ï¸  è·³è¿‡ ${filename}: æ²¡æœ‰æœ‰æ•ˆå†…å®¹`);
    return;
  }

  if (rawChunks.length !== chunks.length) {
    console.log(
      `   âœ‚ï¸  ä¾æ® ${maxTokensPerChunk} tokens ä¸Šé™é‡æ‹† chunks: ${rawChunks.length} â†’ ${chunks.length}`
    );
  }

  console.log(
    `ğŸ“„ å¤„ç† ${filename}: ${chunks.length} ä¸ªchunks, ${content.length} å­—ç¬¦`
  );

  // å¦‚æœchunkså¤ªå¤šï¼Œåˆ†æ‰¹å¯¼å…¥ï¼ˆæ¯æ¬¡50ä¸ªchunksï¼‰
  // æ³¨æ„ï¼šå½“å‰APIä¼šæ›¿æ¢æ‰€æœ‰chunksï¼Œæ‰€ä»¥éœ€è¦å…ˆåˆ›å»ºæ–‡æ¡£ï¼Œç„¶ååˆ†æ‰¹è¿½åŠ 
  if (chunks.length > 50) {
    console.log(`   âš ï¸  chunksæ•°é‡è¾ƒå¤š(${chunks.length})ï¼Œåˆ†æ‰¹å¯¼å…¥...`);
    await ingestMarkdownFileInBatches(
      externalId,
      title,
      filename,
      filePath,
      chunks,
      generateEmbeddings
    );
    return;
  }

  // æ„å»ºè¯·æ±‚ä½“
  const payload = {
    document: {
      externalId,
      title,
      sourceUrl: `file://${filePath}`,
      metadata: {
        filename,
        fileSize: content.length,
        chunkCount: chunks.length,
      },
    },
    chunks: chunks.map((chunk, index) => ({
      content: chunk.content,
      order: chunk.order,
      tokenCount: estimateTokenCount(chunk.content),
      metadata: {
        ...chunk.metadata,
        chunkIndex: index,
      },
    })),
    generateEmbeddings,
  };

  try {
    const response = await fetch(`${API_BASE_URL}/knowledge/documents`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(payload),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(
        `HTTP ${response.status}: ${errorText || response.statusText}`
      );
    }

    const result = await response.json();
    console.log(
      `âœ… æˆåŠŸå¯¼å…¥ ${filename}: æ–‡æ¡£ID ${result.document.id}, ${result.chunks.length} chunks`
    );
  } catch (error) {
    console.error(`âŒ å¯¼å…¥ ${filename} å¤±è´¥:`, error);
    throw error;
  }
}

/**
 * åˆ†æ‰¹å¯¼å…¥å¤§æ–‡ä»¶
 * ç”±äºAPIä¼šæ›¿æ¢æ‰€æœ‰chunksï¼Œæ‰€ä»¥éœ€è¦ç´¯ç§¯æ‰€æœ‰chunkså†ä¸€æ¬¡æ€§æäº¤
 */
async function ingestMarkdownFileInBatches(
  externalId: string,
  title: string,
  filename: string,
  filePath: string,
  chunks: Chunk[],
  generateEmbeddings: boolean
): Promise<void> {
  const batchSize = 50;
  let allImportedChunks: Chunk[] = [];

  console.log(`   ğŸ“¦ å°†åˆ† ${Math.ceil(chunks.length / batchSize)} æ‰¹å¯¼å…¥...`);

  // åˆ†æ‰¹å¤„ç†ï¼Œä½†ç´¯ç§¯æ‰€æœ‰chunksåä¸€æ¬¡æ€§æäº¤
  for (let i = 0; i < chunks.length; i += batchSize) {
    const batch = chunks.slice(i, i + batchSize);
    allImportedChunks.push(...batch);

    console.log(
      `   ğŸ“ å¤„ç†æ‰¹æ¬¡ ${Math.floor(i / batchSize) + 1}/${Math.ceil(chunks.length / batchSize)}: ${batch.length} chunks (ç´¯ç§¯ ${allImportedChunks.length}/${chunks.length})`
    );

    // æ„å»ºå®Œæ•´payloadï¼ˆåŒ…å«æ‰€æœ‰å·²å¤„ç†çš„chunksï¼‰
    const payload = {
      document: {
        externalId,
        title,
        sourceUrl: `file://${filePath}`,
        metadata: {
          filename,
          fileSize: chunks.reduce((sum, c) => sum + c.content.length, 0),
          chunkCount: chunks.length,
          importedChunks: allImportedChunks.length,
        },
      },
      chunks: allImportedChunks.map((chunk, idx) => ({
        content: chunk.content,
        order: chunk.order,
        tokenCount: estimateTokenCount(chunk.content),
        metadata: {
          ...chunk.metadata,
          chunkIndex: idx,
        },
      })),
      // åªåœ¨æœ€åä¸€æ‰¹ç”Ÿæˆembeddings
      generateEmbeddings:
        i + batchSize >= chunks.length ? generateEmbeddings : false,
    };

    try {
      const response = await fetch(`${API_BASE_URL}/knowledge/documents`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload),
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`HTTP ${response.status}: ${errorText}`);
      }

      const result = await response.json();
      console.log(
        `   âœ… æ‰¹æ¬¡ ${Math.floor(i / batchSize) + 1} å®Œæˆ: ${allImportedChunks.length} chunkså·²å¯¼å…¥`
      );

      // å¦‚æœè¿™æ˜¯æœ€åä¸€æ‰¹ï¼Œå®Œæˆ
      if (i + batchSize >= chunks.length) {
        console.log(
          `âœ… æˆåŠŸå¯¼å…¥ ${filename}: æ–‡æ¡£ID ${result.document.id}, ${result.chunks.length} chunks`
        );
        break;
      }
    } catch (error) {
      console.error(`âŒ æ‰¹æ¬¡ ${Math.floor(i / batchSize) + 1} å¤±è´¥:`, error);
      throw error;
    }
  }
}

/**
 * ä¼°ç®—tokenæ•°é‡ï¼ˆç®€å•ä¼°ç®—ï¼šä¸­æ–‡çº¦1.5å­—ç¬¦/tokenï¼Œè‹±æ–‡çº¦4å­—ç¬¦/tokenï¼‰
 */
function estimateTokenCount(text: string): number {
  const chineseChars = (text.match(/[\u4e00-\u9fa5]/g) || []).length;
  const otherChars = text.length - chineseChars;
  return Math.ceil(chineseChars / 1.5 + otherChars / 4);
}

function enforceTokenLimit(chunks: Chunk[], maxTokens: number): Chunk[] {
  const normalized: Chunk[] = [];

  for (const chunk of chunks) {
    const pieces = splitChunkByTokenLimit(chunk.content, maxTokens);
    pieces.forEach((content, idx) => {
      if (!content.trim()) return;
      normalized.push({
        content: content.trim(),
        order: normalized.length,
        metadata: {
          ...chunk.metadata,
          originalOrder: chunk.order,
          splitIndex: idx,
        },
      });
    });
  }

  return normalized.map((chunk, index) => ({
    ...chunk,
    order: index,
  }));
}

function splitChunkByTokenLimit(text: string, maxTokens: number): string[] {
  const cleaned = text.trim();
  if (!cleaned) {
    return [];
  }

  if (estimateTokenCount(cleaned) <= maxTokens) {
    return [cleaned];
  }

  const paragraphGroups = groupByToken(
    cleaned.split(/\n{2,}/),
    '\n\n',
    maxTokens
  );
  const results: string[] = [];

  for (const group of paragraphGroups) {
    if (!group.trim()) continue;
    if (estimateTokenCount(group) <= maxTokens) {
      results.push(group.trim());
      continue;
    }

    const sentenceGroups = groupByToken(
      group.split(/(?<=[ã€‚ï¼ï¼Ÿ!?\.])\s+/),
      ' ',
      maxTokens
    );

    for (const sentenceBlock of sentenceGroups) {
      if (!sentenceBlock.trim()) continue;
      if (estimateTokenCount(sentenceBlock) <= maxTokens) {
        results.push(sentenceBlock.trim());
      } else {
        results.push(
          ...splitByCharacters(sentenceBlock, maxTokens).map(part =>
            part.trim()
          )
        );
      }
    }
  }

  return results.filter(Boolean);
}

function groupByToken(
  segments: string[],
  joiner: string,
  maxTokens: number
): string[] {
  const result: string[] = [];
  let current: string[] = [];
  let currentTokens = 0;

  for (const rawSegment of segments) {
    const segment = rawSegment.trim();
    if (!segment) {
      continue;
    }

    const tokens = estimateTokenCount(segment);
    if (tokens > maxTokens) {
      if (current.length) {
        result.push(current.join(joiner).trim());
        current = [];
        currentTokens = 0;
      }
      result.push(segment);
      continue;
    }

    if (currentTokens + tokens <= maxTokens || currentTokens === 0) {
      current.push(segment);
      currentTokens += tokens;
    } else {
      result.push(current.join(joiner).trim());
      current = [segment];
      currentTokens = tokens;
    }
  }

  if (current.length) {
    result.push(current.join(joiner).trim());
  }

  return result;
}

function splitByCharacters(text: string, maxTokens: number): string[] {
  const maxChars = Math.max(200, maxTokens);
  const parts: string[] = [];

  for (let start = 0; start < text.length; start += maxChars) {
    const slice = text.slice(start, start + maxChars).trim();
    if (slice) {
      parts.push(slice);
    }
  }

  return parts.length ? parts : [text];
}

/**
 * ä¸»å‡½æ•°
 */
async function main() {
  const args = process.argv.slice(2);
  const generateEmbeddings = !args.includes('--no-embeddings');
  const maxTokensArg = args
    .find(arg => arg.startsWith('--max-tokens='))
    ?.split('=')[1];
  if (maxTokensArg) {
    const parsed = Number.parseInt(maxTokensArg, 10);
    if (Number.isFinite(parsed) && parsed > 0) {
      maxTokensPerChunk = parsed;
    }
  }
  const specificFiles = args.filter(arg => !arg.startsWith('--'));

  try {
    // è·å–æ‰€æœ‰Markdownæ–‡ä»¶
    const files = await readdir(KNOWLEDGE_DIR);
    const mdFiles = specificFiles.length
      ? specificFiles.map(f => (f.endsWith('.md') ? f : `${f}.md`))
      : files.filter(f => f.endsWith('.md'));

    if (mdFiles.length === 0) {
      console.error(`âŒ åœ¨ ${KNOWLEDGE_DIR} ä¸­æ²¡æœ‰æ‰¾åˆ°Markdownæ–‡ä»¶`);
      process.exit(1);
    }

    console.log(
      `ğŸš€ å¼€å§‹å¯¼å…¥ ${mdFiles.length} ä¸ªMarkdownæ–‡ä»¶${generateEmbeddings ? ' (ç”Ÿæˆembeddings)' : ''}...\n`
    );

    let successCount = 0;
    let failCount = 0;

    for (const file of mdFiles) {
      const filePath = path.join(KNOWLEDGE_DIR, file);
      try {
        await ingestMarkdownFile(filePath, generateEmbeddings);
        successCount++;
      } catch (error) {
        failCount++;
        console.error(`  é”™è¯¯è¯¦æƒ…:`, error);
      }
      console.log(''); // ç©ºè¡Œåˆ†éš”
    }

    console.log(`\nğŸ“Š å¯¼å…¥å®Œæˆ: ${successCount} æˆåŠŸ, ${failCount} å¤±è´¥`);
  } catch (error) {
    console.error('âŒ å¯¼å…¥è¿‡ç¨‹å‡ºé”™:', error);
    process.exit(1);
  }
}

main().catch(error => {
  console.error(error);
  process.exit(1);
});
